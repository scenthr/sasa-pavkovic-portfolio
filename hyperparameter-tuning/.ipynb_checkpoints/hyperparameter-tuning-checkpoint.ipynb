{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameters of a model\n",
    "\n",
    "#### Trying out different hyperparameters of a model to find the best set of hyperparameters to use\n",
    "\n",
    "#### Tags:\n",
    "    Data: labeled data, Kaggle competition\n",
    "    Technologies: python, pandas, scikit-learn\n",
    "    Techniques: hyperparameter tuning\n",
    "    \n",
    "#### Resources:\n",
    "[Kaggle competition data - Predicting Pulsar stars](https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star/data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters of a model\n",
    "\n",
    "Different models and machine learning techniques have different ways of calculating the target variable (in predictive analytics) and this also means there are a certain set of levers that exist in each tecnique that allows us to fit the data better to the task and the data at hand - hyperparameters.\n",
    "\n",
    "Hyperparameters are different from parameters in that they are not a part of the model (think parametric models like linear regression), and they do not have to be estimated. But none the less they can be used to change the out of functions that are used in different models.\n",
    "\n",
    "### Tuning the hyperparameters\n",
    "\n",
    "The process of changing the hyperparameters is called hyperparameter tuning, as in we are changing the hyperparameters to maximize the metric we evaluate the model by. In essence we change the levers of a model to fit the model better to data at hand. \n",
    "\n",
    "### Hyperparameter tuning for algorithms in classification\n",
    "\n",
    "#### Predicting if the star is a pulsar based \n",
    "\n",
    "We will use the Kaggle data to tune the hyperparameters of the following models:\n",
    "    \n",
    "    1. LogisticRegression\n",
    "    2. GradientBoostingClassifier\n",
    "    3. KNeighboursClassifier\n",
    "    \n",
    "So lets take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17898 entries, 0 to 17897\n",
      "Data columns (total 9 columns):\n",
      " Mean of the integrated profile                  17898 non-null float64\n",
      " Standard deviation of the integrated profile    17898 non-null float64\n",
      " Excess kurtosis of the integrated profile       17898 non-null float64\n",
      " Skewness of the integrated profile              17898 non-null float64\n",
      " Mean of the DM-SNR curve                        17898 non-null float64\n",
      " Standard deviation of the DM-SNR curve          17898 non-null float64\n",
      " Excess kurtosis of the DM-SNR curve             17898 non-null float64\n",
      " Skewness of the DM-SNR curve                    17898 non-null float64\n",
      "target_class                                     17898 non-null int64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "# import the relevant dataset\n",
    "df = pd.read_csv('../data/pulsar_stars.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are 17898 observations and 9 columns in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "X = df.drop(['target_class'],axis=1)\n",
    "y = df['target_class']\n",
    "\n",
    "# Scaling the data\n",
    "X_scaled = pd.DataFrame(StandardScaler().fit_transform(X),columns=X.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the parameters to cycle through Grid Search \n",
    "\n",
    "For each of the models we set the hyperparameters we want to tune and the values we whish to tune. In this way a matrix of possible combination of parameters is built and the model is created with those hyperparameters. Then each model is evaluated through cross-validation and the hyperparameters of the best model are stored and available at the end. In sklearn this is called GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the needed classifiers\n",
    "classifiers = {}\n",
    "classifiers['Logistic Regression'] = LogisticRegression(random_state=42)\n",
    "classifiers['Gradient Boosting'] = GradientBoostingClassifier(random_state=42)\n",
    "classifiers['KNN'] = KNeighborsClassifier()\n",
    "\n",
    "# setting the wanted hyperparameters\n",
    "hyperparams = {}\n",
    "hyperparams['Logistic Regression'] = {\n",
    "                                        'penalty': ['l1', 'l2'],\n",
    "                                        'C': [0.1, 0.25, 0.5],\n",
    "                                        'solver': ['liblinear']\n",
    "                                    }\n",
    "hyperparams['Gradient Boosting'] = {\n",
    "                                'loss': ['deviance', 'exponential'],\n",
    "                                'learning_rate': [0.05, 0.1, 0.3],\n",
    "                                'n_estimators':[10, 20, 50],\n",
    "                                'min_samples_split':[10, 50, 100]\n",
    "                               }\n",
    "hyperparams['KNN'] = {\n",
    "                        'n_neighbors': [5, 10, 20],\n",
    "                        'weights': ['uniform', 'distance']\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the different models\n",
    "\n",
    "def train_predict_gscv(classifiers, hyperparams, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    Given a model train the model given the data\n",
    "    '''\n",
    "    \n",
    "    best_params={}\n",
    "    test_score={}\n",
    "    for model in classifiers:\n",
    "        \n",
    "# use GridSearchCV class to create and object with certain parameters        \n",
    "        gscv = GridSearchCV(estimator=classifiers[model],param_grid=hyperparams[model],scoring='roc_auc',cv=10,verbose=1)         \n",
    "\n",
    "# fit the GridSearchCV using the above provided params    \n",
    "        gscv.fit(X_train, y_train)  \n",
    "\n",
    "# store the best parameters    \n",
    "        best_params[model] = gscv.best_params_        \n",
    "        \n",
    "# predict with the best model found        \n",
    "        y_hat = gscv.predict(X_test)\n",
    "        \n",
    "        test_score[model] = roc_auc_score(y_test,y_hat)\n",
    "        \n",
    "    return best_params, test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   10.7s finished\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "best_params, test_score = train_predict_gscv(classifiers, hyperparams, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'C': 0.5, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       " 'Gradient Boosting': {'learning_rate': 0.3,\n",
       "  'loss': 'exponential',\n",
       "  'min_samples_split': 50,\n",
       "  'n_estimators': 50},\n",
       " 'KNN': {'n_neighbors': 20, 'weights': 'distance'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.9146838995582806,\n",
       " 'Gradient Boosting': 0.9206075865635448,\n",
       " 'KNN': 0.8955320468886067}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model\n",
    "\n",
    "By inspecting the AUC score we found out that all of the models perform extremely well, with Gradient Boosting achieving AUC score of 0.92. Interesting is that both Logistic Regression and KNN are not that far away from that score. The data set is such that classifying if a star is a pulsar can be done very nicely.\n",
    "\n",
    "More details on the different hyperparameters for each of the models can be found below:\n",
    "\n",
    "[Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "[Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "\n",
    "[KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
