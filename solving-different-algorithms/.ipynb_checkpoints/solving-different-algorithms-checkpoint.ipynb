{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem with different algorithms\n",
    "\n",
    "#### Using different algorithms in classification and finding the one that performs the best\n",
    "\n",
    "#### Tags:\n",
    "    Data: labeled data, Kaggle competition\n",
    "    Technologies: python, pandas, scikit-learn\n",
    "    Techniques: runing different algorithms on the same data \n",
    "    \n",
    "#### Resources:\n",
    "[Kaggle competition data](https://www.kaggle.com/uciml/mushroom-classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different algorithms\n",
    "\n",
    "Each problem and each data set is special, hence knowing how to apply different statistical approaches and machine learning algorithms helps identify a method or set of methods that performs best on the data set given. \n",
    "\n",
    "With the dataset at hand we will do a classification to predict one of 2 classes, e - edible and p - poisonus. The main idea here is to show how different algorithms can be used to identify the best one. All the algorithms will be used out of the box and no parameter tuning will be done (as this will be looked into in detail in a separate project). We will use AUC as a metric to identify which model performs best.\n",
    "\n",
    "We will be using 3 different classifiers for the task:\n",
    "    1. Logistic Regression - an extension of the multiple linear regression as a Generalized Linear Model\n",
    "    2. Random Forest - an ensemble of Decision Trees\n",
    "    3. K-Nearest Neighbours - another non-parametric approach that calculates Euclidean distance between the observation and its k nearest neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      "class                       8124 non-null object\n",
      "cap-shape                   8124 non-null object\n",
      "cap-surface                 8124 non-null object\n",
      "cap-color                   8124 non-null object\n",
      "bruises                     8124 non-null object\n",
      "odor                        8124 non-null object\n",
      "gill-attachment             8124 non-null object\n",
      "gill-spacing                8124 non-null object\n",
      "gill-size                   8124 non-null object\n",
      "gill-color                  8124 non-null object\n",
      "stalk-shape                 8124 non-null object\n",
      "stalk-root                  8124 non-null object\n",
      "stalk-surface-above-ring    8124 non-null object\n",
      "stalk-surface-below-ring    8124 non-null object\n",
      "stalk-color-above-ring      8124 non-null object\n",
      "stalk-color-below-ring      8124 non-null object\n",
      "veil-type                   8124 non-null object\n",
      "veil-color                  8124 non-null object\n",
      "ring-number                 8124 non-null object\n",
      "ring-type                   8124 non-null object\n",
      "spore-print-color           8124 non-null object\n",
      "population                  8124 non-null object\n",
      "habitat                     8124 non-null object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# import the relevant dataset\n",
    "df = pd.read_csv('../data/mushrooms.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are 8124 observations and 23 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "X = df.drop(['class'],axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Encode the categorical data (creates a large matrix)\n",
    "# X = pd.get_dummies(X) - here i deliberately did not use one hot encoding as then the auc score is 1!\n",
    "# for all the models\n",
    "X = X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spavko/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/spavko/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train the different models\n",
    "\n",
    "def train_predict(classifiers, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    Given a model train the model given the data\n",
    "    '''\n",
    "    \n",
    "    scores = {}\n",
    "    class_report = {}\n",
    "    for model in classifiers:\n",
    "        classifiers[model].fit(X_train, y_train)    \n",
    "        y_hat = classifiers[model].predict(X_test)\n",
    "\n",
    "        scores[model] = roc_auc_score(y_test,y_hat)\n",
    "        class_report[model] = confusion_matrix(y_test,y_hat)\n",
    "        \n",
    "    return scores, class_report\n",
    "\n",
    "classifiers = {}\n",
    "classifiers['Logistic Regression'] = LogisticRegression(random_state=42)\n",
    "classifiers['Random Forrest'] = RandomForestClassifier(random_state=42)\n",
    "classifiers['KNN'] = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "scores, class_report = train_predict(classifiers, X_train, y_train, X_test, y_test)\n",
    "#for idx, model in enumerate(classifiers):\n",
    "#    classifiers[model].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.9464553885920761,\n",
       " 'Random Forrest': 1.0,\n",
       " 'KNN': 0.9982206405693951}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[798  45]\n",
      " [ 42 740]]\n",
      "[[843   0]\n",
      " [  0 782]]\n",
      "[[840   3]\n",
      " [  0 782]]\n"
     ]
    }
   ],
   "source": [
    "for i in class_report:\n",
    "    print(class_report[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model\n",
    "\n",
    "By inspecting the AUC score we found out that all of the models perform extremely well, with Random Forrest achieveing the perfect AUC score. It seems this data set is such that classifying between edible and poisonus mushrooms is an easy task.\n",
    "\n",
    "Confusion matrix also shows the usual TP, FP, TN, FN data cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
