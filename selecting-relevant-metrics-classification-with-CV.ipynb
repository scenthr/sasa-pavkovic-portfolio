{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the relevant metric in classification\n",
    "\n",
    "#### Select the relevant metric for classification problems in order to compare multiple models performance\n",
    "\n",
    "#### Tags:\n",
    "    Data: labeled data, Kaggle competition\n",
    "    Technologies: python, pandas, scikit-learn\n",
    "    Techniques: selecting the relevant metric for calssification \n",
    "    \n",
    "#### Resources:\n",
    "[UCI Machine Learning Repository - Default of Credit Clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#)\n",
    "\n",
    "[ROC curve and AUC](https://www.youtube.com/watch?v=OAl6eAyP-yo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrics for model evaluation\n",
    "\n",
    "The metrics for classification are more elaborate than for regression. The main idea is comparing the predictions with acutal classes where usually the rows are the actual class while the columns are the predicted class. In the simplest classification task where the class is binary we have 4 cells in the confusion matrix, true positive, false negative, false positive and false negative. The perfect classifier would have only values on the main diagonal.\n",
    "\n",
    "An example of the below confusion matrix can be found here:\n",
    "[Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "![title](confusion-matrix.png)\n",
    "\n",
    "Hence the main metrics are:\n",
    "\n",
    "1. Accuracy - has issues with the skewed datasets, where there is a low probability of a certain class\n",
    "2. Precision - is the accuracy of the positive predictions\n",
    "3. Recall - sensitivity or TPR is the proportion of positive istances that are correctly detected by the classifier\n",
    "4. TNR - specificty or TNR is the ration of negative instances that are correctly predicted as negative\n",
    "5. FPR - false positive rate, ratio of false positive instances out of all negative instances\n",
    "\n",
    "Increasing precision decreases recall and vice-versa. Depending on the type of problem we are trying to solve we can prefer higer precision or higher recall. We can plot the Precision / Recall graph for different levels of precision and recall to understand the behavior of the model and pick the balance that suits our needs best.\n",
    "\n",
    "Finally the usually used metric in evaluating classification models is Area under the Curve (AUC), that comes from the ROC curve. ROC curve plots TPR (Recall) against FPR for each threshold of the TPR. As this metric is also available in the Scikit-learn library we will use it to compare different classification models.\n",
    "\n",
    "Lets take a closer look in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      "ID                            30000 non-null int64\n",
      "LIMIT_BAL                     30000 non-null int64\n",
      "SEX                           30000 non-null int64\n",
      "EDUCATION                     30000 non-null int64\n",
      "MARRIAGE                      30000 non-null int64\n",
      "AGE                           30000 non-null int64\n",
      "PAY_0                         30000 non-null int64\n",
      "PAY_2                         30000 non-null int64\n",
      "PAY_3                         30000 non-null int64\n",
      "PAY_4                         30000 non-null int64\n",
      "PAY_5                         30000 non-null int64\n",
      "PAY_6                         30000 non-null int64\n",
      "BILL_AMT1                     30000 non-null int64\n",
      "BILL_AMT2                     30000 non-null int64\n",
      "BILL_AMT3                     30000 non-null int64\n",
      "BILL_AMT4                     30000 non-null int64\n",
      "BILL_AMT5                     30000 non-null int64\n",
      "BILL_AMT6                     30000 non-null int64\n",
      "PAY_AMT1                      30000 non-null int64\n",
      "PAY_AMT2                      30000 non-null int64\n",
      "PAY_AMT3                      30000 non-null int64\n",
      "PAY_AMT4                      30000 non-null int64\n",
      "PAY_AMT5                      30000 non-null int64\n",
      "PAY_AMT6                      30000 non-null int64\n",
      "default payment next month    30000 non-null int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "# import the relevant dataset\n",
    "df = pd.read_excel('../data/default-of-credit-card-clients.xls',skiprows=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are 30000 observations and there are all numeric in character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('default payment next month',axis=1)\n",
    "\n",
    "y = df['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into the trainging and evaluation sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the parameters for the grid search for each of the classifiers\n",
    "\n",
    "modelnames = ['LR', 'KNN', 'SVM', 'RF', 'GB']\n",
    "\n",
    "models = {'LR':LogisticRegression(random_state=42),\n",
    "         'KNN':KNeighborsClassifier(),\n",
    "         'SVM':SVC(random_state=42),\n",
    "         'RF':RandomForestClassifier(random_state=42),\n",
    "         'GB':GradientBoostingClassifier(random_state=42)}\n",
    "\n",
    "parameters = {'LR':{'C':[0.1,1,2]},\n",
    "             'KNN':{'n_neighbors':[3,5,7]},\n",
    "             'SVM':{'kernel':['linear','poly','rbf']},\n",
    "             'RF':{'max_depth':[3,5,7]},\n",
    "             'GB':{'learning_rate':[0.05,0.1,0.2]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed:    2.0s finished\n",
      "/home/spavko/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    }
   ],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "results = {}\n",
    "\n",
    "for m in models:\n",
    "      \n",
    "    cv = GridSearchCV(models[m],parameters[m], cv=3, scoring=scoring, refit='AUC', verbose=2, n_jobs=3)\n",
    "    \n",
    "    cv.fit(X_train, y_train)\n",
    "    \n",
    "    results[m] = cv.cv_results_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
